{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Classification<h1>\n",
    "<h6>Daniel Santoso - 2201756506<h6>\n",
    "<h6>Axel Jeremy - 2201756140<h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "allData = pd.read_csv('E202-COMP7117-TD01-00 - classification.csv')\n",
    "data = allData[['volatile acidity', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']]\n",
    "\n",
    "def load_dataset():\n",
    "    x_data = data[['volatile acidity', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']]\n",
    "    y_data = data[['quality']]\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method utk update weight (feed forward)\n",
    "def feed_forward():\n",
    "    W_x1 = tf.matmul(X, weight['hidden'])\n",
    "    W_x1_b = W_x1 + bias['hidden']\n",
    "    y1 = tf.nn.sigmoid(W_x1_b)\n",
    "    \n",
    "    W_x2 = tf.matmul(y1, weight['output'])\n",
    "    W_x2_b = W_x2 + bias['output']\n",
    "    y2 = tf.nn.sigmoid(W_x2_b)\n",
    "\n",
    "    return y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Selection<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      volatile acidity  chlorides free sulfur dioxide  total sulfur dioxide  \\\n",
      "0                0.700      0.076              Medium                  34.0   \n",
      "1                0.880      0.098             Unknown                  67.0   \n",
      "2                0.760      0.092                High                  54.0   \n",
      "3                0.280      0.075                High                  60.0   \n",
      "4                0.700      0.076              Medium                  34.0   \n",
      "...                ...        ...                 ...                   ...   \n",
      "1594             0.600      0.090             Unknown                  44.0   \n",
      "1595             0.550      0.062             Unknown                  51.0   \n",
      "1596             0.510      0.076             Unknown                  40.0   \n",
      "1597             0.645      0.075             Unknown                  44.0   \n",
      "1598             0.310      0.067                High                  42.0   \n",
      "\n",
      "        density          pH  sulphates  alcohol quality  \n",
      "0          High  Very Basic       0.56      9.4  Decent  \n",
      "1          High      Normal       0.68      9.8  Decent  \n",
      "2          High      Normal       0.65      9.8  Decent  \n",
      "3     Very High      Normal       0.58      9.8    Fine  \n",
      "4          High  Very Basic       0.56      9.4  Decent  \n",
      "...         ...         ...        ...      ...     ...  \n",
      "1594        Low      Normal       0.58     10.5  Decent  \n",
      "1595        Low  Very Basic       0.76     11.2    Fine  \n",
      "1596     Medium      Normal       0.75     11.0    Fine  \n",
      "1597        Low  Very Basic       0.71     10.2  Decent  \n",
      "1598        Low      Normal       0.66     11.0    Fine  \n",
      "\n",
      "[1599 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['free sulfur dioxide'] = data['free sulfur dioxide'].map({'High': 3, 'Medium': 2, 'Low': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "data['free sulfur dioxide'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['density'] = data['density'].replace({'Very High': 0, 'High': 3, 'Medium': 2, 'Low': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['pH'] = data['pH'].map({'Very Basic': 3, 'Normal': 2, 'Very Accidic': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pH'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "      volatile acidity  chlorides  free sulfur dioxide  total sulfur dioxide  \\\n",
      "0                0.700      0.076                  2.0                  34.0   \n",
      "1                0.880      0.098                  0.0                  67.0   \n",
      "2                0.760      0.092                  3.0                  54.0   \n",
      "3                0.280      0.075                  3.0                  60.0   \n",
      "4                0.700      0.076                  2.0                  34.0   \n",
      "...                ...        ...                  ...                   ...   \n",
      "1594             0.600      0.090                  0.0                  44.0   \n",
      "1595             0.550      0.062                  0.0                  51.0   \n",
      "1596             0.510      0.076                  0.0                  40.0   \n",
      "1597             0.645      0.075                  0.0                  44.0   \n",
      "1598             0.310      0.067                  3.0                  42.0   \n",
      "\n",
      "      density   pH  sulphates  alcohol quality  \n",
      "0           3  3.0       0.56      9.4  Decent  \n",
      "1           3  2.0       0.68      9.8  Decent  \n",
      "2           3  2.0       0.65      9.8  Decent  \n",
      "3           0  2.0       0.58      9.8    Fine  \n",
      "4           3  3.0       0.56      9.4  Decent  \n",
      "...       ...  ...        ...      ...     ...  \n",
      "1594        1  2.0       0.58     10.5  Decent  \n",
      "1595        1  3.0       0.76     11.2    Fine  \n",
      "1596        2  2.0       0.75     11.0    Fine  \n",
      "1597        1  3.0       0.71     10.2  Decent  \n",
      "1598        1  2.0       0.66     11.0    Fine  \n",
      "\n",
      "[1599 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.isna().values.any())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feature Extraction using PCA (4 Principal Component)<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features dari dataset\n",
    "x_data, y_data = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisasi data menggunakan StandardScaler\n",
    "x_data = StandardScaler().fit_transform(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis data menggunakan PCA untuk memperoleh komponen-komponen baru yang paling penting (4 komponen)\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "principalComponents = pca.fit_transform(x_data)\n",
    "\n",
    "principalData = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2', 'pc3', 'pc4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masukkan hasil analisis PCA ke dalam dataframe yang akan diolah menggunakan algoritma klasifikasi BPNN\n",
    "finalData = pd.concat([principalData, data[['quality']]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           pc1       pc2       pc3       pc4 quality\n",
      "0    -1.651446 -1.015835  1.303395 -0.418110  Decent\n",
      "1     0.241284  0.830076  1.302104 -0.294581  Decent\n",
      "2    -0.279387 -1.280738  0.872046 -0.023036  Decent\n",
      "3    -0.388067 -0.251456 -0.786297  0.356763    Fine\n",
      "4    -1.651446 -1.015835  1.303395 -0.418110  Decent\n",
      "...        ...       ...       ...       ...     ...\n",
      "1594 -0.126125  1.106746 -0.198183 -0.173263  Decent\n",
      "1595 -0.604354  0.935475  0.683259 -0.395856    Fine\n",
      "1596  0.187583  0.666876  0.369840 -0.359556    Fine\n",
      "1597 -0.658217  0.809147  0.593976 -0.418809  Decent\n",
      "1598 -0.402239 -0.856664 -0.454222  0.123227    Fine\n",
      "\n",
      "[1599 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(finalData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>BPNN Architecture<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = finalData[['pc1', 'pc2', 'pc3', 'pc4']]\n",
    "target = finalData[['quality']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "layer = {\n",
    "    'numof_input': 4,\n",
    "    'numof_hidden': 1,\n",
    "    'numof_output': 5\n",
    "}\n",
    "\n",
    "weight = {\n",
    "    'hidden': tf.Variable(tf.random_normal([layer['numof_input'], layer['numof_hidden']])),\n",
    "    'output': tf.Variable(tf.random_normal([layer['numof_hidden'], layer['numof_output']]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'hidden': tf.Variable(tf.random_normal([layer['numof_hidden']])),\n",
    "    'output': tf.Variable(tf.random_normal([layer['numof_output']]))\n",
    "}\n",
    "\n",
    "learning_rate = 0.5\n",
    "epoch = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target dari string menjadi angka\n",
    "encode = OneHotEncoder(sparse=False)\n",
    "encode = encode.fit(target)\n",
    "target = encode.transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data menjadi training data (70%), validation data (20%), dan evaluation data (10%)\n",
    "x_train, x_test0, y_train, y_test0 = train_test_split(feats, target, test_size=0.3)\n",
    "x_val, x_ev, y_val, y_ev = train_test_split(x_test0, y_test0, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, layer['numof_input']])\n",
    "y_true = tf.placeholder(tf.float32, [None, layer['numof_output']])\n",
    "\n",
    "y_feed = feed_forward()\n",
    "\n",
    "# Untuk menghitung error dan set optimizernya dengan GradientDescentOptimizer\n",
    "loss = tf.reduce_mean((0.5*(y_true-y_feed) ** 2)) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Untuk save modelnya\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 || Error: 0.09076221287250519\n",
      "Epoch: 200 || Error: 0.07139885425567627\n",
      "Epoch: 300 || Error: 0.06733978539705276\n",
      "Epoch: 400 || Error: 0.06593364477157593\n",
      "Epoch: 500 || Error: 0.06524897366762161\n",
      "---------------------------------\n",
      "Epoch: 500 || Validation Error: 0.06353585422039032\n",
      "---------------------------------\n",
      "Epoch: 600 || Error: 0.0648425742983818\n",
      "Epoch: 700 || Error: 0.06457039713859558\n",
      "Epoch: 800 || Error: 0.06437264382839203\n",
      "Epoch: 900 || Error: 0.06422016769647598\n",
      "Epoch: 1000 || Error: 0.06409697234630585\n",
      "---------------------------------\n",
      "Epoch: 1000 || Validation Error: 0.06213339418172836\n",
      "---------------------------------\n",
      "Epoch: 1100 || Error: 0.06399369984865189\n",
      "Epoch: 1200 || Error: 0.06390450894832611\n",
      "Epoch: 1300 || Error: 0.06382562965154648\n",
      "Epoch: 1400 || Error: 0.06375455111265182\n",
      "Epoch: 1500 || Error: 0.06368947774171829\n",
      "---------------------------------\n",
      "Epoch: 1500 || Validation Error: 0.061540935188531876\n",
      "---------------------------------\n",
      "Epoch: 1600 || Error: 0.06362923979759216\n",
      "Epoch: 1700 || Error: 0.0635729730129242\n",
      "Epoch: 1800 || Error: 0.06352003663778305\n",
      "Epoch: 1900 || Error: 0.06346996128559113\n",
      "Epoch: 2000 || Error: 0.06342238187789917\n",
      "---------------------------------\n",
      "Epoch: 2000 || Validation Error: 0.061110399663448334\n",
      "---------------------------------\n",
      "Epoch: 2100 || Error: 0.06337708234786987\n",
      "Epoch: 2200 || Error: 0.06333381682634354\n",
      "Epoch: 2300 || Error: 0.06329245865345001\n",
      "Epoch: 2400 || Error: 0.06325287371873856\n",
      "Epoch: 2500 || Error: 0.06321489065885544\n",
      "---------------------------------\n",
      "Epoch: 2500 || Validation Error: 0.060750726610422134\n",
      "---------------------------------\n",
      "Epoch: 2600 || Error: 0.06317851692438126\n",
      "Epoch: 2700 || Error: 0.06314356625080109\n",
      "Epoch: 2800 || Error: 0.06311005353927612\n",
      "Epoch: 2900 || Error: 0.06307785212993622\n",
      "Epoch: 3000 || Error: 0.06304691731929779\n",
      "---------------------------------\n",
      "Epoch: 3000 || Validation Error: 0.06044250726699829\n",
      "---------------------------------\n",
      "Epoch: 3100 || Error: 0.06301718950271606\n",
      "Epoch: 3200 || Error: 0.06298861652612686\n",
      "Epoch: 3300 || Error: 0.06296113133430481\n",
      "Epoch: 3400 || Error: 0.06293470412492752\n",
      "Epoch: 3500 || Error: 0.06290922313928604\n",
      "---------------------------------\n",
      "Epoch: 3500 || Validation Error: 0.06017763167619705\n",
      "---------------------------------\n",
      "Epoch: 3600 || Error: 0.06288469582796097\n",
      "Epoch: 3700 || Error: 0.06286106258630753\n",
      "Epoch: 3800 || Error: 0.06283824890851974\n",
      "Epoch: 3900 || Error: 0.06281621009111404\n",
      "Epoch: 4000 || Error: 0.06279494613409042\n",
      "---------------------------------\n",
      "Epoch: 4000 || Validation Error: 0.059948213398456573\n",
      "---------------------------------\n",
      "Epoch: 4100 || Error: 0.06277433782815933\n",
      "Epoch: 4200 || Error: 0.06275438517332077\n",
      "Epoch: 4300 || Error: 0.06273503601551056\n",
      "Epoch: 4400 || Error: 0.06271623075008392\n",
      "Epoch: 4500 || Error: 0.0626978948712349\n",
      "---------------------------------\n",
      "Epoch: 4500 || Validation Error: 0.05974532291293144\n",
      "---------------------------------\n",
      "Epoch: 4600 || Error: 0.06268000602722168\n",
      "Epoch: 4700 || Error: 0.06266248226165771\n",
      "Epoch: 4800 || Error: 0.06264524906873703\n",
      "Epoch: 4900 || Error: 0.06262824684381485\n",
      "Epoch: 5000 || Error: 0.06261134892702103\n",
      "---------------------------------\n",
      "Epoch: 5000 || Validation Error: 0.0595601387321949\n",
      "---------------------------------\n",
      "Accuracy: 52.20125961303711%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for i in range(1, epoch + 1):\n",
    "        sess.run(train, feed_dict={X: x_train, y_true: y_train})\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            matches = tf.equal(tf.argmax(y_feed, axis=1), \n",
    "                tf.argmax(y_true, axis=1)\n",
    "            )\n",
    "\n",
    "            accuracy = tf.reduce_mean(tf.cast(matches, tf.float32))\n",
    "\n",
    "            print('Epoch: {} || Error: {}'.format(i, sess.run(loss, feed_dict={X: x_train, y_true: y_train})))\n",
    "        \n",
    "        if i % 500 == 0:\n",
    "            valError = sess.run(loss, feed_dict={X: x_val, y_true: y_val})\n",
    "            \n",
    "            print('---------------------------------')\n",
    "            print('Epoch: {} || Validation Error: {}'.format(i, valError))\n",
    "            print('---------------------------------')\n",
    "            \n",
    "            if(i == 500 or valError < last):\n",
    "                last = valError\n",
    "                saver.save(sess, \"model-saved/model.ckpt\")\n",
    "    \n",
    "    print('Accuracy: {}%'.format(sess.run(accuracy*100, feed_dict={X: x_ev, y_true: y_ev})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
